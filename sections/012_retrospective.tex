\chapter{Retrospective}
\label{chap:retrospective}

\epigraph{I can live with doubt and uncertainty and not knowing. \\ I think it is much more interesting to live not knowing than to have answers that might be wrong.}{\textit{Richard P. Feynman}}

In this section, we provide a retrospective on the \cref{chap:classification,chap:regression,chap:robustness,chap:graph_data,chap:sequential_data,chap:reinforcement_learning} since their publications by discussing potential improvements and the related works published a posteriori.

\section{Uncertainty estimation for classification and regression} 

\paragraph{Potential improvements.} The proposed methods \PostNetacro{} (see \cref{chap:classification}) and \NatPNacro{} (see \cref{chap:regression}) for uncertainty estimation for classification and regression are composed of several components (e.g. encoder/decoder, density estimator, prior, loss, optimizer) with potential improvements, First, more expressive density estimator like recent normalizing flows \cite{nf-review} and diffusion models \cite{variationaldiffussion2022kingma} could improve uncertainty estimation. Second, it would be interesting to explore better choices of prior which have been shown to have a significant impact in other Bayesian neural networks \cite{bayesposterior2020wenzel, coldaleatoric2020adlam}. Further, the design of Bayesian loss have shown up to be an important choice for uncertainty estimation \cite{bengs2022pitfalls}. Finally, it would be interesting to explore the effect of feature collapse \cite{due} which have still an unclear effect on the predictive and uncertainty performances.

\paragraph{Recent related works.} Recently, the approaches presented in this thesis have been  at the core of a survey on evidential deep learning \cite{survey_evidential_uncertainty} and implemented in google uncertainty benchmark \cite{nado2021uncertainty}. Similar to our approach, other works have also subsequently explored Bayesian neural networks which are not fully stochastic \cite{bnnfullystochastic2022sharma} and uncertainty estimation methods with density estimation \cite{du2022vos, postels2020hiddenuncertainty, uncertainty-generative-classifier}. Some other works explored efficient uncertainty estimation by proposing to train a single larger network \cite{abe2022deep}, an ensemble of subnetworks \cite{mimo-independent-subnetworks}, training energy-based models \cite{ood_ebm}, or pruning neural networks \cite{ayle2022robustness-sparse}. Further, multiple methods proposed to use conformal predictions to provide uncertainty estimates for any trained model by using an additional calibration set \cite{conformal-survey, Park2020PAC}. Finally, other recent works \cite{minderer2021revisiting, tran2022plex} had a close look at the evaluation of uncertainty estimation for modern and large pretrained models.

\paragraph{A view on the current field status.} We believe that the field of uncertainty estimation for classification and regression is very active and has solved many issues concerning the flexibility, the efficiency, and the scalability of uncertainty methods.

\section{Robustness of uncertainty estimation} 

\paragraph{Potential improvements.} The proposed methods and evaluations for the robustness of uncertainty estimation (see \cref{chap:robustness}) has two main directions of improvements. First, it would be interesting to extend the benchmark to other recent uncertainty methods and datasets. This would allow to give a more extensive view on the weaknesses of existing uncertainty methods. Second, no approaches have shown significant gain in uncertainty robustness. Indeed, adversarial training and smoothing approaches detailed in \cref{chap:robustness} have shown only small improvement.

\paragraph{Recent related works.} Recently, \cite{galil2021disrupting} and \cite{huimin2022attackingOOD} proposed attacks on uncertainty estimations which are very similar to our approach without proposing solutions for robust uncertainty estimation. Only \cite{meinke2021provably} has proposed another method for certifiable uncertainty estimation. On a different direction, \cite{dia2021localizeduncertainty} proposed to use input uncertainty to design less perceptible adversarial attacks. Finally, \cite{alarab2021attackucertainty} proposed to provide uncertainty estimates based on adversarial attacks.

\paragraph{A view on the current field status.} We believe that the field of adversarial robustness for uncertainty estimation has achieved fast progress regarding the uncertainty attacks. Nonetheless, it is still a very new field and adversarial robustness of uncertainty estimates is still unsolved. 

\section{Uncertainty for graph data.}

\paragraph{Potential improvements.} The proposed method \GPNacro{} (see \cref{chap:graph_data}) has two main directions of improvements. First, \GPNacro{} focuses on homophilic graphs. Recent works have proposed methods \cite{bodnar2022sheaf, giovanni2022graff} working on both homophilic and heterophilic graphs but do not provide uncertainty estimates. Second, it would be interesting to extend our proposed benchmark for uncertainty estimation on more datasets including very large scale datasets. Recently, \cite{gui2022good} has proposed to extend OOD detection benchmarks for graph datasets.


\paragraph{Recent related works.} Recent works \cite{texeira2019GNNmiscalibrated, hsu2022GNNmiscalibrated, wang2021confident} had a deeper focused on calibration for GNNs. They observed that GNNs are miscalibrated and can be recalibrated temperature rescaling. Other works \cite{zhou2022OODlink, hsu2022structure} have extended our approach by proposing uncertainty on edges for calibration and OOD detection. Finally, other approaches \cite{soleimany2021evidential} focused on uncertainty estimation for graph-level tasks like molecular property prediction.

\paragraph{A view on the current field status.} Even if this topic is still very recent, We believe that the field of uncertainty estimation for graph is evolving fast with many new models and evaluations for uncertainty estimation at node level, edge level, and graph level. 

\section{Uncertainty for sequential data.}

\paragraph{Potential improvements.} The approaches proposed in \cref{chap:sequential_data} for uncertainty estimation has two main directions of improvement. First, while the uncertainty on the event type is represented via explicit and expressive categorical distributions, the uncertainty on the event time is represented via implicit temporal point processes distributions with contained intensity functions. To solve this issue, \cite{shchur2020intensity} and \cite{shchur2020fast} extended our work by modelling expressive point processes which are intensity free and point processes where likelihood computation, sampling, and prediction can all be done efficiently in closed form. Second, it would be interesting to extend the benchmark for uncertainty estimation for event sequences. Recently, \cite{shchur2021detecting} had a closer look at anomalous event detection in both simulated and real-world data and \cite{shchur2021review} provided an overview of application areas for temporal point processes. 

\paragraph{Recent related works.} Beyond sequential data with time events, other works have recently looked at uncertainty estimation for sequential data with text. For example, \cite{malinin2021uncertainty} models uncertainty at token and sequence level with applications to translation datasets. Further, \cite{he2020toward, hu2021uncertainty} proposed uncertainty methods for text classification.

\paragraph{A view on the current field status.} We believe that the field of uncertainty estimation for sequential data has achieved fast progress for both time event data and text data. Nonetheless, the emergence of powerful large language models have demonstrated unreliable behaviors which urges further development of uncertainty methods. 

\section{Uncertainty for reinforcement learning.}

\paragraph{Potential improvements.} The uncertainty framework proposed in \cref{chap:reinforcement_learning} has several directions of improvements. First, similarly to generalization benchmarks for RL \cite{generalization-rl-survey, assessing-generalization-rl, procgen}, it would be interesting to extend this uncertainty benchmark for RL to more complex environments. Second, our uncertainty framework is limited to model-free RL methods and could be extended to model-based RL methods. 

\paragraph{Recent related works.} Recently, \cite{tennenholtz2022plan} and \cite{wu2022plan} proposed a new uncertainty methods for model-based RL. Similar to our approach, another work \cite{liu2022uncertaintyaware} used aleatoric and epistemic uncertainty with density estimation  in RL for player evaluation in games. Finally, another work \cite{luo2022distributional} developed other method for distributional RL.

\paragraph{A view on the current field status.} We believe that although uncertainty estimation for RL has already a long history, the benefit of uncertainty estimation in RL is still under-explored without well-established desiderata and large-scale benchmarks.