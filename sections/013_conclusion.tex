\chapter{Conclusion}
\label{chap:conclusion}

\epigraph{The more I see the less I know for sure.}{\textit{John Lennon}}

\epigraph{I know one thing, that I know nothing.}{\textit{Socrates}}

\section{Reliable ML beyond uncertainty estimation}

Accurate uncertainty estimation aims at improving trust in safety-critical domains subject to automation, in application of ML models in areas requiring fairness, or in a maintenance context where the underlying data distribution might slowly shift over time. In this regard, this thesis significantly improves the applicability of uncertainty estimation across a wide range of input (e.g. tabular, images, graph data, sequential data, etc) and output domains (e.g. classification, regression, count prediction, etc) while maintaining a fast inference time. This could be particularly beneficial in industrial applications with time pressure and potential critical consequences (e.g. finance, medicine, policy decision-making, etc).

Nonetheless, while methods described in this thesis achieve high-quality uncertainty estimation, there is always a risk that they do not fully capture the real-world complexity e.g. for OOD data close to ID data. Furthermore, we raise awareness about two other risks of excessive trust related to the \emph{Dunning-Kruger effect} \citep{dunning-kruger}: human excessive trust in Machine Learning model capacity, and human excessive trust in its own interpretation capacity. Therefore, we encourage practitioners to proactively confront the model design and its uncertainty estimates to desired behaviors in real-world use cases.

Further, beyond uncertainty estimation, multiple other aspects play a critical role in the reliability of ML models including robustness, interpretability, privacy, green AI, or AI alignment.

\paragraph{Robustness.} While \cref*{chap:robustness} focuses on the robustness of uncertainty estimates, robustness is a more general field which aims to guarantee that any types of model predictions do not change when imperceptible perturbations are applied to the input data. This covers empirical robustness and certifiable robustness against both natural and adversarial perturbations \cite{tu2020empirical, chun2020empirical, cohen2019, zugner2020certifiable}. Robustness is a very active field of research with many studies on robustness for independent data \cite{silva2020opportunies} but also for dependent data like graph data \cite{GNNBook-ch8-gunnemann} or sequential data \cite{cheng2020}.

\paragraph{Interpretability.} Interpretability is important in ML to explain the reasons for model predictions. It ensures impartial decision-making and indicate if meaningful variables are used to infer the prediction output. It covers different types of explanations like text explanations, visual explanations, local explanations or explanations by example. Interpretability and explainability are also very active fields with many existing studies \cite{arrieta2019explainable, overview-interpretable-ml}

\paragraph{Privacy.} Privacy consists in preventing an attacker to infer facts about members of a population, about data in the training set, or about the model parameters \cite{cristofaro2020privacy, cristofaro2021privacy}. Privacy is important to avoid data leakage in both centralized and federated learning. An important defense against privacy attackers is differential privacy \cite{buglesi2006privacy} which tried to learn useful information from the whole training dataset without retaining specific information about individual samples.

% \paragraph{Green AI.} Building green AI models with low CO2 emissions and low energy consumption is key to propose reliable AI solutions with sustainable long term impact on the environment. Green AI is particularly important since computations required for deep learning research have been doubling every few months \cite{schwartz2019greenAI}. Existing techniques to reduce required computations for ML models include quantization, distillation, and model pruning \cite{neill2020compression}. 

\paragraph{AI alignment.} AI alignment aim to align the intended goals of the AI designers,  the specified goals to the AI system, and the emergent goals that the AI system actually advances \cite{bostrom2014superintelligence, gabriel2020AI}. This field is still at its infancy. Recent works on AI alignment involve large foundational models (e.g. \cite{gpt, rombach2021highresolution, galactica}) which might show misaligned behavior which can be (partially) realigned similarly to InstructGPT \cite{instructgpt} or ChatGPT \cite{chatgpt}.

% \section{Broader Impact}

% Accurate uncertainty estimation aims at improving trust in safety-critical domains subject to automation, and in a maintenance context where the underlying data distribution might slowly shift over time. In this regard, this thesis significantly improves the applicability of uncertainty estimation across a wide range of input (e.g. tabular, images, graph data, sequential data, etc) and output domains (e.g. classification, regression, count prediction, etc) while maintaining a fast inference time. This could be particularly beneficial in industrial applications with time pressure and potential critical consequences (e.g. finance, medicine, policy decision-making, etc).

% Nonetheless, while methods described in this thesis achieve high-quality uncertainty estimation, there is always a risk that they do not fully capture the real-world complexity e.g. for OOD data close to ID data. Furthermore, we raise awareness about two other risks of excessive trust related to the \emph{Dunning-Kruger effect} \citep{dunning-kruger}: human excessive trust in Machine Learning model capacity, and human excessive trust in its own interpretation capacity. Therefore, we encourage practitioners to proactively confront the model design and its uncertainty estimates to desired behaviors in real-world use cases.

\section{Open Questions}

Beyond the potential improvements mentioned in \cref{chap:retrospective_1,chap:retrospective_2}, we identified other open questions related to uncertainty estimation in ML which are not directly treated in this thesis.

\paragraph{How to estimate uncertainty for large foundational models?} Recently, many large foundational models have been developed (e.g. \cite{gpt, rombach2021highresolution, galactica}) with already high impact on real-world applications like art creation, text writing, coding, or scientific research. It is important to develop uncertainty methods adapted to these methods to avoid misusage of their (potentially wrong) predictions. Hence, multiple recent works already started to develop promising methods to efficiently estimate uncertainty for large models with a focus on languages models (e.g. \citep{kuhn2023semantic,kadavath2022language}). Nonetheless, the emergence of foundational models for different data types and applications motivates further research on uncertainty methods for large models especially when their defined goals might be misaligned with the intended goals.

\paragraph{How to continually learn in the presence of uncertainty?} Intuitively, uncertainty is expected to help to continually learn on a series of tasks (e.g. \cite{ebrahimi2020uncertainty-guided,khan2021knowledge,farquhar2018towards}) or actively select useful data for training (e.g. \cite{jain2022biological,gal2017bald,kirsch2019batch,kirsch2021simple,tata2022can}). Indeed, low uncertainty should indicate already learned inputs, while high uncertainty should indicate unknown data regions. However, the study of uncertainty estimation to achieve state-of-the-arts performance is still an important research direction.

\paragraph{Why is the model uncertain?} Uncertainty estimates on the predictions might be sensitive to small input data perturbations (see \cref{chap:robustness}) which makes unclear whether uncertainty predictions are always based on valid reasons. Hence, it is crucial to have reliable explanations on the causes of the uncertainty predictions. However, apart from \cite{antoran2021getting} which proposed a first method to interpret uncertainty estimates and \cite{marx2022but} which aim to construct uncertainty set which contains the correct explanation with high probability, there have been very few works on generating explanations on the causes of uncertainty estimates. 

\paragraph{How to estimate uncertainty on inferred causal relationships?} Causal inference aims at inferring causal relationships from observed data. However, the observed data might not be sufficient to have a clear conclusion on the causal relationship between two variables, thus making them non-identifiable \cite{pearl2009causality}. Only very few works defined distributions on DAGs to provide uncertainty estimates \cite{charpentier2022dpdag}. Hence, the area of uncertainty estimation for causal inference is still underexplored.

% \epigraph{Madness is the consequence not of uncertainty but of certainty.}{\textit{Friedrich W. Nietzsche}}

% \epigraph{As far as the laws of mathematics refer to reality, they are not certain; and as far as they are certain, they do not refer to reality.}{\textit{Albert Einstein}}

% \epigraph{Science is the outcome of being prepared to live without certainty and therefore a mark of maturity. It embraces doubt and loose ends.}{\textit{A.C. Grayling}}

% \epigraph{To know what you know and what you do not know, that is true knowledge}{\textit{Confucius}}

% \epigraph{The only true wisdom is in knowing you know nothing.}{\textit{Socrates}}

% \epigraph{Ignorance more frequently begets confidence than does knowledge.}{\textit{Charles Darwin}}

% \epigraph{Uncertainty is the only certainty there is, and knowing how to live with insecurity is the only security.}{\textit{John Allen Paulos}}

% \epigraph{Doubt is not a pleasant condition, but certainty is absurd.}{\textit{Voltaire}}

% \epigraph{Uncertainty that comes from knowledge (knowing what you don't know) is different from uncertainty coming from ignorance.}{\textit{Isaac Asimov}}

% \epigraph{Knowledge progresses by integrating uncertainty into itself, not by exorcising it}{\textit{Edgar Morin}}

% \epigraph{I can live with doubt and uncertainty and not knowing. I think it is much more interesting to live not knowing than to have answers that might be wrong.}{\textit{Richard P. Feynman}}

% \epigraph{The more I see the less I know for sure.}{\textit{John Lennon}}

% \epigraph{I know one thing, that I know nothing.}{\textit{Socrates}}
