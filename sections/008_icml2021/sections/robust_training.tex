\subsection{Robust training for DBU models \& ID/OOD Verification}

Our robustness analysis based on label attacks and uncertainty attacks shows that neither the predicted class, nor the uncertainty corresponding to a prediction, nor the differentiation between ID and OOD-data is robust. 
Thus, we propose adversarial training  procedures to enhance robustness. During training we augment the data set by samples computed based on (i) PGD attacks against the crossentropy loss or (ii) against the differential entropy function, which is used to distinguish between ID and OOD data, or (iii) by adding random noise as proposed for randomized smoothing training. 


 \begin{table*}[ht!]
	\centering
	\caption{Randomized smoothing verification for different $\sigma$ of CIFAR10 (ID data) and SVHN (OOD data). Left part: percentage of samples that is \textit{correctly} identified and certified as ID data (cc) and corresponding mean certified radius (R). Right part: same for OOD data.}
	\begin{tiny}
		\begin{tabular}{@{}rrrcrrcrrc|crrcrrcrr@{}}
			\toprule
			& \multicolumn{8}{c}{ID-Verification} &  & &  \multicolumn{8}{c}{OOD-Verification} \\
			\cmidrule{2-10}  \cmidrule{12-19}
			$\sigma$ & \multicolumn{2}{c}{\textbf{0.1}} & & \multicolumn{2}{c}{\textbf{0.2}} & & \multicolumn{2}{c}{\textbf{0.5}} & & & 
			\multicolumn{2}{c}{\textbf{0.1}} & & \multicolumn{2}{c}{\textbf{0.2}} & & \multicolumn{2}{c}{\textbf{0.5}} \\ 
			\cmidrule{2-3}  \cmidrule{5-6} \cmidrule{8-9} 
			\cmidrule{12-13}  \cmidrule{15-16} \cmidrule{18-19}  
			& cc & R  & & cc & R  & & cc & R  & & & 
			cc & R  & & cc & R  & & cc & R   \\ 
			\midrule 
			%
			& \multicolumn{18}{c}{\textbf{adv. train. loss: None}} \\ 
			\PriorNet  & \bf{83.2} & \bf{0.26} & & \bf{97.8} & \bf{0.58} & & \bf{100.0} & \bf{1.47}  & 
			& & 3.7 & 0.10 & & 0.0 & 0.00 & & 0.0 & 0.00 \\ 
			\PostNet  & 23.6 & 0.17 & & 22.2 & 0.11 & & 0.0 & 0.00  & 
			& & \bf{99.3} & \bf{0.23} & & \bf{99.2} & \bf{0.29} & & \bf{100.0} & \bf{1.37} \\ 
			\DDNet  & 63.7 & 0.24 & & 88.7 & 0.50 & & 53.0 & 0.32  & 
			& & 27.9 & 0.17 & & 8.7 & 0.16 & & 77.6 & 0.58 \\ 
			\EvNet  & 53.2 & 0.15 & & 58.3 & 0.20 & & 13.1 & 0.14  & 
			& & 54.9 & 0.11 & & 48.1 & 0.21 & & 94.3 & 0.59 \\ 
			\midrule 
			& \multicolumn{18}{c}{\textbf{adv. train. loss: rand. smooth.}} \\ 
			\PriorNet  & 1.5 & 0.06 & & 0.8 & 0.05 & & \bf{89.3} & \bf{0.73}  & 
			& & \bf{97.5} & \bf{0.28} & & \bf{99.4} & \bf{0.34} & & 38.7 & 0.22 \\ 
			\PostNet  & 63.3 & 0.26 & & 51.8 & 0.46 & & 65.3 & 0.86  & 
			& & 93.4 & 0.26 & & 92.9 & 0.48 & & 73.2 & 0.63 \\ 
			\DDNet  & \bf{68.6} & \bf{0.26} & & \bf{58.0} & \bf{0.43} & & 80.5 & 0.90  & 
			& & 86.3 & 0.16 & & 88.1 & 0.36 & & 45.1 & 0.33 \\ 
			\EvNet  & 58.9 & 0.27 & & 56.6 & 0.45 & & 63.9 & 0.98  & 
			& & 92.9 & 0.27 & & 74.4 & 0.46 & & \bf{85.6} & \bf{0.81} \\ 
			\midrule
			& \multicolumn{18}{c}{\textbf{adv. train. loss: crossentropy}} \\ 
			\PriorNet  & \bf{99.8} & \bf{0.38} & & 0.0 & 0.00 & & \bf{31.1} & \bf{0.25}  & 
			& & 0.0 & 0.00 & & \bf{100.0} & \bf{0.76} & & 60.7 & 0.21 \\ 
			\PostNet  & 22.2 & 0.15 & & 51.2 & 0.21 & & 0.0 & 0.00  & 
			& & \bf{99.4} & \bf{0.22} & & 44.9 & 0.18 & & 100.0 & 1.44 \\ 
			\DDNet  & 49.0 & 0.20 & & 33.8 & 0.25 & & 0.0 & 0.00  & 
			& & 45.4 & 0.18 & & 61.6 & 0.39 & & \bf{100.0} & \bf{1.91} \\ 
			\EvNet  & 29.4 & 0.12 & & \bf{84.2} & \bf{0.26} & & 2.4 & 0.09  & 
			& & 96.6 & 0.16 & & 8.4 & 0.10 & & 100.0 & 0.55 \\ 
			\midrule 
			& \multicolumn{18}{c}{\textbf{adv. train. loss: diffE}} \\ 
			\PriorNet  & 1.1 & 0.04 & & 0.0 & 0.00 & & \bf{100.0} & \bf{1.91}  & 
			& & \bf{99.2} & \bf{0.31} & & \bf{100.0} & \bf{0.76} & & 0.0 & 0.00 \\ 
			\PostNet  & 30.3 & 0.17 & & 6.1 & 0.13 & & 0.0 & 0.00  & 
			& & 94.9 & 0.17 & & 99.8 & 0.55 & & 100.0 & 1.17 \\ 
			\DDNet  & 37.1 & 0.22 & & 4.4 & 0.23 & & 0.0 & 0.00  & 
			& & 81.5 & 0.24 & & 100.0 & 0.65 & & \bf{100.0} & \bf{1.80} \\ 
			\EvNet  & \bf{38.6} & \bf{0.31} & & \bf{22.6} & \bf{0.15} & & 1.0 & 0.11  & 
			& & 77.9 & 0.32 & & 91.8 & 0.21 & & 99.8 & 0.62 \\ 
			%
			\bottomrule
		\end{tabular}
	\end{tiny}
	\label{tab:rand_smoothing_ioood_cifar10}
\end{table*}


Since attacks are used during robust training, we want to avoid tying robustness evaluation to gradient based attacks. Instead, we propose {the first approach that certifies robustness of DBU models} based on randomized smoothing \citep{cohen2019}.
Randomized smoothing was proposed to verify robustness w.r.t. class predictions and we modify it for ID/OOD-verification. As randomized smoothing treats classifiers as a black-box, we transform distinguishing between ID data (label 0) and OOD data (label 1) into a binary classification problem based on an uncertainty measure, which requires to set a threshold for the uncertainty measure to obtain an actual decision boundary. This is in contrast to our attack-based experiments where we avoided setting thresholds by analyzing area under the curve metrics. Thresholds for uncertainty measure are set for each model individually based on the validation set, such that the accuracy w.r.t.\ to ID/OOD-assignment of the model is maximized. 


In the following we discuss results for ID/OOD-verification based on differential entropy on CIFAR10 (ID data) and SVHN (OOD data). Further  results on other data sets, other uncertainty measures and results on the standard classification based randomized smoothing verification are shown in the appendix. 
%
Table~\ref{tab:rand_smoothing_ioood_cifar10} shows the percentage of samples which are correctly identified as ID (resp. OOD) data and are certifiably robust within this type (cc; certified correct) 
along with the corresponding mean certified radius. The higher the portion of cc samples and the larger the radius the more robust is ID/OOD-distinguishing w.r.t. the corresponding perturbation size~$\sigma$.\footnote{We want to highlight again that attacks are here only used to enable robust training of the models. The robustness evaluation itself operates on the original data (not attacked and, thus, seemingly easy); only smoothed via randomized smoothing. The verification  provides us a radius that guarantees robustness around the sample.}  




For each model, we observe a performance jump between ID- and OOD-verification, where robustness on ID data drops from high values to low ones while the cc percentage and radius on OOD-data increase. These jumps are observed for normal training as well as adversarial training based on the crossentropy or the differential entropy. Thus, either ID-verification or OOD-verification performs well, depending on the chosen threshold. 
Augmenting the data set with random noise perturbed samples (randomized smoothing loss) does not result in such performance jumps (except for \PriorNet), but there is also a trade-off between robustness on ID data versus robustness on OOD data and there is no parametrization where ID-verification and OOD-verification perform equally well. 




 \begin{table*}[ht!]
 	\centering
 	\caption{Randomized smoothing verification for different $\sigma$ of CIFAR10 (ID data) and SVHN (OOD data):  percentage of samples that is \textit{wrongly} identified as ID/OOD and certifiably robust as this \textit{wrong} type (cw) and corresponding mean certified radius (R). The lower cw, the more robust the model.}
 	\begin{tiny}
        \begin{tabular}{@{}rrrcrrcrrc|crrcrrcrr@{}}
 			\toprule
$\sigma$ & \multicolumn{2}{c}{\textbf{0.1}} & & \multicolumn{2}{c}{\textbf{0.2}} & & \multicolumn{2}{c}{\textbf{0.5}} & & & 
\multicolumn{2}{c}{\textbf{0.1}} & & \multicolumn{2}{c}{\textbf{0.2}} & & \multicolumn{2}{c}{\textbf{0.5}} \\ 
\cmidrule{2-3}  \cmidrule{5-6} \cmidrule{8-9} 
\cmidrule{12-13}  \cmidrule{15-16} \cmidrule{18-19}  
 & cw & R  & & cw & R  & & cw & R  & & & 
   cw & R  & & cw & R  & & cw & R   \\ 
\midrule 
& \multicolumn{8}{c}{\textbf{adv. train. loss: None}} & & \multicolumn{8}{c}{\textbf{adv. train. loss: rand. smooth.}} \\ 
\PriorNet  & \bf{15.9} & \bf{0.13} & & \bf{1.9} & \bf{0.18} & & \bf{0.0} & \bf{0.00}  & &
           & 98.2 & 0.33 & & 98.6 & 0.53 & & \bf{8.0} & \bf{0.22}  \\ 
\PostNet  & 74.9 & 0.17 & & 73.5 & 0.21 & & 100.0 & 1.30  & &
          & 35.7 & 0.16 & & 46.7 & 0.34 & & 32.3 & 0.47  \\ 
\DDNet  & 35.1 & 0.14 & & 10.1 & 0.17 & & 41.6 & 0.35  & & 
        & \bf{29.9} & \bf{0.11} & & \bf{40.5} & \bf{0.31} & & 17.6 & 0.32 \\
\EvNet  & 43.0 & 0.09 & & 37.2 & 0.15 & & 82.8 & 0.52  & & 
        & 39.5 & 0.22 & & 41.4 & 0.33 & & 34.2 & 0.50 \\  
\midrule 
& \multicolumn{8}{c}{\textbf{adv. train. loss: crossentropy}} & & \multicolumn{8}{c}{\textbf{adv. train. loss: diffE}} \\ 
\PriorNet  & \bf{0.1} & \bf{0.12} & & 100.0 & 0.76 & & \bf{62.2} & \bf{0.33}  &  & 
           & 98.4 & 0.31 & & 100.0 & 0.74 & & \bf{0.0} & \bf{0.00} \\ 
\PostNet  & 76.4 & 0.18 & & 45.0 & 0.18 & & 100.0 & 1.28  & & 
            & 68.0 & 0.15 & & 93.5 & 0.42 & & 100.0 & 1.10  \\ 
\DDNet  & 49.5 & 0.16 & & 64.3 & 0.37 & & 100.0 & 1.91  & &
        & \bf{61.2} & \bf{0.19} & & 95.5 & 0.57 & & 100.0 & 1.84  \\ 
\EvNet  & 68.3 & 0.12 & & \bf{12.9} & \bf{0.11} & & 95.6 & 0.39  & &
        & 61.2 & 0.33 & & \bf{73.8} & \bf{0.18} & & 97.9 & 0.60  \\
%
 			\bottomrule
 		\end{tabular}
 	\end{tiny}
 	\label{tab:rand_smoothing_wrong_cifar10}
 \end{table*}





While Table~\ref{tab:rand_smoothing_ioood_cifar10} shows the percentage of samples which are correctly identified and certified as ID/OOD data (cc), Table~\ref{tab:rand_smoothing_wrong_cifar10} shows the percentage of samples which are wrongly identified as ID/OOD data and certifiably robust as this wrong type (cw; certified wrong). These cw samples are worse than adversarial examples. 
Neither robust training based on label attacks, uncertainty attacks nor noise perturbed samples consistently reduce the portion of certifiably wrong samples, even worse it seems to increase the number of cw samples. 
Thus, although robust training improves DBU-model resistance against label attacks (see Appendix, Table~\ref{tab:rand_smoothing_class_cifar10_2}), ID/OOD-verification shows that each model is either robust on ID-data or on OOD-data. Achieving robustness on both types is challenging. 
Our results rise the following question: How do we make DBU models robust w.r.t.\ class label predictions and ID/OOD-differentiation without favoring either performance on ID data or OOD data? 


