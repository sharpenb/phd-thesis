% PRIOR -----------------------------------
\section{Prior for DUMs}
\label{sec:prior}

In this section, we study the effect that the prior component has in DUMs. More specifically, we investigate the relationships between aleatoric uncertainty and the prior specified for DUMs. In particular, this is motivated by \citet{kapoor2022prior_cpe} which shows that using priors that forces model to be confident on the training data points can improve its performance by explicitly accounting for aleatoric uncertainty.
To this end, we look at \textit{entropy regularization} defining a training prior in the loss, \textit{prior evidence} and \textit{kernel function} defining a functional prior in the uncertainty head.

\textbf{Prior.} We compare different prior specifications including \textit{entropy regularization} defining a training prior in the loss, \textit{prior evidence} and \textit{kernel function} defining a functional prior in the uncertainty head. Entropy regularization is the entropy term $H(Q)$ in the Bayesian loss used to train NatPN which encourages a (uniform) prior distributions with high entropy \citep{NatPN2021}. We control the strength of the regularization factor $\lambda$. Further, NatPN also explicitly defines a prior via the parameters $\chi^{prior}$ and $n^{prior}$. While  $\chi^{prior}$ defines the default categorical prediction via a uniform categorical distribution, the evidence parameter $n^{prior}$ defines the prior number of pseudo-observations and can be varied. Finally, we vary the prior of DUE by using different kernel functions in the learned GP including Matern kernel, RQ kernel, and RBF \citep{gp-for-ml}. \underline{\textit{Observation:}} Contrary to other Bayesian neural networks \citep{kapoor2022prior_cpe}, we observe that predictive and uncertainty performances of DUMs are not very sensitive to the prior specification (see \cref{fig:prior_ood,fig:prior_ood_brier,tab:kernel}), thus suggesting a higher robustness to prior mispecification. Nonetheless, a too strong entropy regularization toward an uniform prior degrades more performance of DUMs trained on dataset with low label noise than on high label noise. This suggests that a too high discrepancy between the model prior and the dataset aleatoric uncertainties can impact performance.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{sections/008_iclr2023/figures/prior_entropy_acc_pred.pdf}
    \includegraphics[width=\textwidth]{sections/008_iclr2023/figures/prior_pseudo_acc_pred.pdf}
    
    \caption{Results of enforcing different \textbf{prior} in NatPN on CIFAR100 by changing the (top) \textit{entropy regularization} $\lambda$ and the (bottom) \textit{evidence prior} $n^{prior}$. Different priors do not lead consistent results improvements.}
    \label{fig:prior_ood}
\end{figure}
 \vspace{-3mm}
\input{sections/008_iclr2023/tables/kernel.tex}