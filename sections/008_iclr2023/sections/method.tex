\section{Deterministic Uncertainty Methods}
\label{sec:dum}

We consider a classification task where the goal is to predict the label $y\dataix \in \{ 1, \ldots , \nclass \}$ based on the input feature $\vx\dataix \in \real^{\inputdim}$. In this case, a DUM generally performs predictions in two main steps: \textbf{(1)} A core \emph{architecture} $f_\mathbf{\phi}$ maps the input features $\vx\dataix \in \real^{\inputdim}$ to a latent representation $\vz\dataix \in \real^{\latentdim}$, i.e. $f_\mathbf{\phi}(\vx\dataix)=\vz\dataix$. In practice, important design choices are the latent dimension $\latentdim$ and the architecture $f_\mathbf{\phi}$ which should be adapted to the task (see \cref{sec:architecture}). Further, multiple works proposed to apply additional bi-Lipschitz or reconstruction constraints to enrich the informativeness of the latent representation $\vz\dataix$ (see \cref{sec:architecture}). \textbf{(2)} An \emph{uncertainty head} $g_\mathbf{\psi}$ maps the latent representation $\vz\dataix$ to a predicted label $\hat{y}\dataix$ and an associated (aleatoric, epistemic, or predictive) uncertainty estimate $u\dataix$, i.e. $g_\mathbf{\psi}(\vz\dataix)=(\hat{y}\dataix, u\dataix)$. In practice, important design choices are the type of uncertainty head which are generally instantiated with a Gaussian Process (GP) \citep{uncertainty-distance-awareness, due, duq, uceloss, charpentier2022uncertainty-rl}, a density estimator \citep{charpentier2020, NatPN2021, charpentier2022uncertainty-rl, graph-postnet, uceloss, mukhoti2021ddu, postels2020mir, contrastive-ood, wu2020contrastive}, or an evidential model \citep{charpentier2020, NatPN2021, charpentier2022uncertainty-rl, graph-postnet, uceloss, malini2018}, and the choice of the prior used by the uncertainty head (see \cref{sec:prior}). Beyond core architecture and uncertainty head, another important choice is the training procedure which can either couple or decouple the parameters of the core architecture and uncertainty head (see \cref{sec:training}).

In this work we focus on two recent DUMs which cover different types of uncertainty heads: Natural Posterior Network (NatPN) \cite{NatPN2021} which learns an evidential distribution based on density estimation on the latent space, and Deterministic Uncertainty Estimator (DUE) \citep{due} which learns a deep Gaussian Process by parametrizing learnable inducing points in the latent space (see \cref{appendix:dums} for further method details). While NatPN is capable to differentiate aleatoric, epistemic, and predictive uncertainty, DUE only outputs the predictive uncertainty. 
For all the experiments, we use the same default setup: we first \emph{pretrain} the encoder with the cross-entropy loss until convergence, then load the pretrained encoder and jointly \emph{train} the encoder and uncertainty head (see \cref{subsec:appendix_training,subsec:appendix_encoder,subsec:appendix_prior} for further component details). We report the predictive performance via accuracy, and the uncertainty performances with Brier Score and OOD detection results after averaging over 5 seeds (see \cref{sec:metric_details} for further metric details). We perform our experiments on MNIST \citep{mnist}, CIFAR10 and CIFAR100 \citep{cifar10}, and Camelyon \citep{wilds}. OOD results reported in 
\cref{tab:training_schema,tab:training_pretrain,tab:encoder_architecture,tab:kernel} averages the uncertainty estimation from five OOD datasets: SVHN, STL10, CelebA, Camelyon and SVHN OODom \citep{svhn, coates2011stl10, celeba}. Our code and additional material is available online\footnote{\url{https://www.cs.cit.tum.de/daml/training-architecture-prior-dum/}}.

\textbf{Related work.} Previous works survey OOD detection methods \citep{ood-detection-survey}, OOD generazilation methods \citep{ood-generalization-survey}, or a wide range of uncertainty estimation methods \citep{uncertainty-survey,psaros2023uncertainty,survey_evidential_uncertainty,review-uncertainty-dl} by presenting key methods and challenges. These surveys do not focus on deterministic methods and do not make empirical analysis.
Other works propose great empirical studies to compare uncertainty estimation methods under shifts \citep{dataset-shift}, or analyze the role of the prior in Bayesian neural networks on weights \citep{bayesposterior2020wenzel, fortuin2022prior, noci2021prior_cpe, kapoor2022prior_cpe}. These works do not focus on DUMs. Closer to our work, \citet{postels2022practicalitydum} compares methods in the DUMs family and demonstrate calibration limitations. In contrast, we evaluate the role of \emph{components} in DUMs and show that carefully specifying \emph{training}, \emph{architecture}, or \emph{prior} can improve uncertainty metrics like calibration and OOD detection but also ID and OOD predictive performances.

% A detailed survey on uncertainty estimation was conducted by \cite{gawlikowski2021survey}, providing a taxonomy for supervised learning uncertainty estimation. A specific survey focusing on DUMs was done by \cite{postels2022practicalitydum}. By following its experimental settings, we evaluate the performance by considering both uncertainty estimation and the calibration on ID and OOD data. Further, we apply different regularization techniques to DUMs and analyze the results from uncertainty estimation and domain generalization evaluated on corrupted \citep{hendrycks2019corrupted} and in-the-wild distribution shifted datasets \citep{koh2021wilds}.
% \citet{minderer2021calibration}
