\subsection{Dataset details}
\label{appendix:dataset}
 We split all the training datasets into train, validation and test sets. For all the datasets, the test set is fixed while the training/validation sets are split in 80/20\% respectively. The random split of training/validation sets change depending on the seeds to ensure more diversity.  
 
\textbf{MNIST} \citep{lecun1998mnist}. Image classification dataset. Similarly as in \cite{arjovsky2019cmnist}, we create the CMNIST dataset for domain generalization experiments by expanding the input's size to 3 x 28 x 28 and zeroing one of the three channels. For OOD detection we use the test set of MNIST as ID dataset and compare to: KMNIST \citep{clanuwat2018kmnist}, CIFAR10, CMNIST, and KMNIST OODom, where we scale the input by 255. The batch size used is 512.

\textbf{CIFAR} \citep{krizhevsky09cifar}. Image classification dataset. We apply two data augmentations methods to the training data:the random horizontal flip and random cropping with padding equal to 4. For domain generalization we use the corrupted version CIFAR-C \citep{hendrycks2019corrupted} and report the average metric of 15 corruptions for the level of corruption severity of 1. For OOD detection we use the test set of CIFAR10 as ID dataset and compare to: SVHN \citep{netzer2011svhn}, STL10 \citep{coates2011stl10}, CelebA \citep{liu2015celeba}, Camelyon (Test OOD), and SVHN OODom. Since the Camelyon (Test OOD) dataset is large (85k), we extract only 10k subset of images as the OOD datasets. The batch size used is 128.

\textbf{Camelyon} \citep{koh2021wilds}. Image classification dataset. We apply two data augmentations emthods  to the training data: random horizontal flip and random rotation of 15 degrees. For domain generalization the dataset already provide the distribution shifted validation and test splits. For OOD detection we use the ID validation set of Camelyon as ID dataset (the ID  test set is not available) and compare to: SVHN, STL10, CelebA, Camelyon (Test OOD), and SVHN OODom. The batch size used is 32.

Each OOD dataset is rescaled to the same size as the ID dataset and normalized with zero mean and unit variance based on the statistics of ID dataset (for the Camelyon dataset we don't apply any normalization as in \cite{koh2021wilds}). 