\subsection{Model details} 

\textbf{Core architecture.} We use the same feature extractor for both the DUMs architecture. The list of core architectures used across the experiments are: \textit{ResNet18 / ResNet50 / EfficientNet / Swin} \citep{resnet, tan2021effcientnet, liu2021swin} from the torchvision repository \footnote{\url{https://pytorch.org/vision/stable/models.html}} and \textit{Wide-ResNet-28-10} \citep{zagoruyko2016wide} from the original implementation of DUE. Except for the experiment on architecture type and size where ResNet18 has output channels for the residual blocks with size $[64,128,256,512]$,  ResNet18 has output channels for the residual blocks with size $[32, 64, 128, 256]$ which causes small differences in final accuracy.

\textbf{Uncertainty head.} For DUE we use the original implementation \footnote{\url{https://github.com/y0ast/DUE}} with by default we use the RBF kernel function. For NatPN we use the original implementation \footnote{\url{https://github.com/borchero/natural-posterior-network}} but change the uncertainty head with a more expressive density estimator. As seen in Table \ref{tab:normalizing_flow}, we found that a more expressive normalizing flow with resampled base \citep{durkan2019nsf, stimper2022resampled-nf} improves significantly the results over a simpler radial normalizing flow \citep{radialflow} across all the metrics. For all the experiments (except toys where we use radial flow) we use NSF-R with 16 layers.

\input{sections/008_iclr2023/tables/normalizing_flow}