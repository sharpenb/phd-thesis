\chapter{Retrospective}
\label{chap:retrospective_1}

% \epigraph{I can live with doubt and uncertainty and not knowing. \\ I think it is much more interesting to live not knowing than to have answers that might be wrong.}{\textit{Richard P. Feynman}}

In this section, we provide a retrospective on the \cref{chap:classification,chap:regression,chap:practicality,chap:robustness} since their publications by discussing potential improvements and the related works published a posteriori.

\section{Uncertainty estimation for classification and regression} 

\paragraph{Potential improvements.} The proposed methods \PostNetacro{} (see \cref{chap:classification}) and \NatPNacro{} (see \cref{chap:regression}) for uncertainty estimation for classification and regression are composed of several components (e.g. encoder/decoder, density estimator, prior, loss, optimizer) with potential improvements, First, more expressive density estimator like recent normalizing flows \cite{nf-review} and diffusion models \cite{variationaldiffussion2022kingma} could improve uncertainty estimation. Second, it would be interesting to explore better choices of prior which have been shown to have a significant impact in other Bayesian neural networks \cite{bayesposterior2020wenzel, coldaleatoric2020adlam}. Further, the design of Bayesian loss has shown to be an important choice for uncertainty estimation \cite{bengs2022pitfalls}. Finally, it would be interesting to explore further the effect of feature collapse \cite{due} which have still an unclear effect on the predictive and uncertainty performances.

\paragraph{Recent related works.} Recently, the approaches presented in this thesis have been  at the core of a survey on evidential deep learning \cite{survey_evidential_uncertainty} and implemented in Google uncertainty benchmark \cite{nado2021uncertainty}. Similar to our approach, other works have also subsequently explored Bayesian neural networks which are not fully stochastic \cite{bnnfullystochastic2022sharma} and uncertainty estimation methods with density estimation \cite{du2022vos, postels2020hiddenuncertainty, uncertainty-generative-classifier}. Some other works explored efficient uncertainty estimation by proposing to train a single larger network \cite{abe2022deep}, an ensemble of subnetworks \cite{mimo-independent-subnetworks}, training energy-based models \cite{ood_ebm}, or pruning neural networks \cite{ayle2022robustness-sparse}. Further, multiple methods proposed to use conformal predictions to provide uncertainty estimates for any trained model by using an additional calibration set \cite{conformal-survey, Park2020PAC}. Finally, other recent works \cite{minderer2021revisiting, tran2022plex} had a close look at the evaluation of uncertainty estimation for modern and large pretrained models.

% \paragraph{A view on the current field status.} We believe that the field of uncertainty estimation for classification and regression is very active and has solved many issues concerning the flexibility, the efficiency, and the scalability of uncertainty methods.

\section{Practicality and Robustness of uncertainty estimation} 

\paragraph{Potential improvements.} The proposed methods and evaluations for the robustness of uncertainty estimation (see \cref{chap:robustness}) has two main directions of improvements. First, it would be interesting to extend the benchmark to other recent uncertainty methods and datasets. This would allow to give a more extensive view on the weaknesses of existing uncertainty methods. Second, no approaches have shown significant gain in uncertainty robustness. Indeed, adversarial training and smoothing approaches detailed in \cref{chap:robustness} have shown only small improvement.

\paragraph{Recent related works.} Recently, \cite{galil2021disrupting} and \cite{huimin2022attackingOOD} proposed attacks on uncertainty estimations which are very similar to our approach without proposing solutions for robust uncertainty estimation. Only \cite{meinke2021provably} has proposed another method for certifiable uncertainty estimation. On a different direction, \cite{dia2021localizeduncertainty} proposed to use input uncertainty to design less perceptible adversarial attacks. Finally, \cite{alarab2021attackucertainty} proposed to provide uncertainty estimates based on adversarial attacks. Despite the fast progress of uncertainty attacks, this field is relatively new and adversarial robustness for uncertainty estimation is still unsolved.