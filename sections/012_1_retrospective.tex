\chapter{Retrospective}
\label{chap:retrospective_1}

% \epigraph{I can live with doubt and uncertainty and not knowing. \\ I think it is much more interesting to live not knowing than to have answers that might be wrong.}{\textit{Richard P. Feynman}}

In this section, we provide a retrospective on the \cref{chap:classification,chap:regression,chap:practicality,chap:robustness} since their publication by discussing potential improvements and the related works published a posteriori.

\section{Uncertainty estimation for classification and regression} 

\paragraph{Potential improvements.} The proposed methods \PostNetacro{} (see \cref{chap:classification}) and \NatPNacro{} (see \cref{chap:regression}) for uncertainty estimation for classification and regression are composed of several components (e.g. encoder/decoder, density estimator, prior, loss, optimizer) with potential improvements. While \cref{chap:practicality} studies the impact of training, architecture, and prior specification for deterministic uncertainty methods, we believe that further improvements can be achieved in these directions. First, more expressive density estimator like other recent normalizing flows \cite{nf-review} and diffusion models \cite{variationaldiffussion2022kingma} could improve uncertainty estimation. Second, it would be interesting to explore if different choices of prior can improve performance as it have been shown to have a significant impact in other Bayesian neural networks \cite{bayesposterior2020wenzel, coldaleatoric2020adlam}. Finally, the design of Bayesian loss has shown to be an important choice for uncertainty estimation \cite{bengs2022pitfalls, bengs2023secondorder}.

\paragraph{Recent related works.} Recently, the approaches presented in this thesis have been  at the core of a survey on evidential deep learning \cite{survey_evidential_uncertainty} and implemented in Google uncertainty benchmark \cite{nado2021uncertainty}. Similar to our approach, other works have also subsequently explored Bayesian neural networks which are not fully stochastic \cite{bnnfullystochastic2022sharma} and uncertainty estimation methods with density estimation \cite{du2022vos, postels2020hiddenuncertainty, uncertainty-generative-classifier}. Some other works explored efficient uncertainty estimation by proposing to train a single larger network \cite{abe2022deep}, an ensemble of subnetworks \cite{mimo-independent-subnetworks}, training energy-based models \cite{ood_ebm}, or pruning neural networks \cite{ayle2022robustness-sparse}. Further, multiple methods proposed to use conformal predictions to provide uncertainty estimates for any trained model by using an additional calibration set \cite{conformal-survey, Park2020PAC}. Finally, other recent works \cite{minderer2021revisiting, tran2022plex} had a close look at the evaluation of uncertainty estimation for modern and large pretrained models. Beyond uncertainty models, \cite{hullermeier2022quantifying} has also analyzed what are appropriate uncertainty measures for epistemic and aleatoric uncertainty in machine learning. 

% \paragraph{A view on the current field status.} We believe that the field of uncertainty estimation for classification and regression is very active and has solved many issues concerning the flexibility, the efficiency, and the scalability of uncertainty methods.

\section{Practicality and Robustness of uncertainty estimation} 

\paragraph{Potential improvements.} First, the study in \cref{chap:practicality} could be extended to account for different task settings involving small datasets, large datasets, or active learning scenarios. Beyond further analysis and improvements of the components of deterministic uncertainty methods, we believe that it would be interesting to extend the practical study in \cref{chap:practicality} with theoretical results. In particular, it might be interesting to show that the trade-off between OOD generalization and OOD detection is not only due to empirically observed feature collapse but is also due to fundamental theoretical limitations. Second, the proposed methods and evaluations for the robustness of uncertainty estimation in \cref{chap:robustness} has two main directions of improvements. First, it would be interesting to extend the benchmark to other recent uncertainty methods and datasets. This would allow to give a more extensive view on the weaknesses of existing uncertainty methods. Second, no approaches have shown significant gain in uncertainty robustness. Indeed, adversarial training and smoothing approaches detailed in \cref{chap:robustness} have shown only small improvement.

\paragraph{Recent related works.} Recently, \cite{galil2021disrupting} and \cite{huimin2022attackingOOD} proposed attacks on uncertainty estimations which are very similar to our approach without proposing solutions for robust uncertainty estimation. Only \cite{meinke2021provably} has proposed another method for certifiable uncertainty estimation. On a different direction, \cite{dia2021localizeduncertainty} proposed to use input uncertainty to design less perceptible adversarial attacks. Finally, \cite{alarab2021attackucertainty} proposed to provide uncertainty estimates based on adversarial attacks. Despite the fast progress of uncertainty attacks, this field is relatively new and adversarial robustness for uncertainty estimation is still unsolved.