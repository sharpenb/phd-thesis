\section{Related Work}
\label{sec:related_work_009}

In this section, we cover the related work for predictive uncertainty estimation for i.i.d. inputs and for graphs. To this end, we review the commonly accepted \emph{desiderata} defining the desired uncertainty estimation under different circumstances, the \emph{methods} capable of consistent uncertainty quantification and the \emph{evaluation} validating the quality of the uncertainty estimates in practice.

\paragraph{Uncertainty for i.i.d. inputs.} The related work for uncertainty quantification on i.i.d. inputs is rich as for example shown in a recent survey \citep{review-uncertainty-dl}. \emph{\underline{Desiderata:}} Far from ID data, the predicted uncertainty is expected to be high \citep{provable-uncertainty, NatPN2021, bayesian-a-bit, sufficient-conditions-no-adversarial}. Close to ID data, the desired uncertainty is more complicated. Indeed, while some works expected models to be robust to small dataset shifts \citep{dataset-shift, stutz2020}, other works expected to detect near OOD classes based on uncertainty \citep{contrastive-ood, robustness-uncertainty-dirichlet, attack-detection}. \emph{\underline{Methods:}} Many methods already exist for uncertainty quantification for i.i.d. inputs like images or tabular data. A first family of models quantifies uncertainty by aggregating statistics (e.g. mean, variance or entropy) from sub-networks with different weights. Important examples are ensemble \citep{ensembles, batch-ensembles, hyper-ensembles, mimo-independent-subnetworks}, dropout \citep{Srivastava2014} or Bayesian Neural Networks (BNN) \citep{bayesian-networks, Depeweg2018, simple-baseline-uncertainty, liberty-depth-bnn, rank-1-bnn}. Most of these approaches require multiple forward-passes for uncertainty quantification. Further, dropout and BNN may have other pitfalls regarding their limited applicability to more complex tasks \citep{Osband2016, Hron2018, practical-bnn, expressiveness-bnn}. A second family quantifies uncertainty by using the logit information. Important examples are temperature scaling which rescale the logits after training \citep{calibration-network, Liang2017} and energy-based models which interpret the logits as energy scores \citep{Liu2020a, energy}. A third family of model quantifies uncertainty based on deep Gaussian Processes (GP). Important examples use GP at activation-level \cite{gp-uncertainty-activation} or at (last) layer-level \citep{uncertainty-distance-awareness, bayesian-a-bit, duq,uceloss}. Finally, a last family of models quantifies uncertainty by directly parameterizing a conjugate prior distribution over the target variable. Important examples explicitly parameterize prior distributions \citep{sensoy2018, distribution-distillation, PriorNetworks, reverse-kl, evidential-regression} or posterior distributions \citep{charpentier2020, NatPN2021}. Methods based on GP and conjugate prior usually have the advantage of deterministic and fast inference. \emph{\underline{Evaluation:}} Previous works have already proposed empirical evaluation of uncertainty estimation by looking at accuracy, calibration or OOD detection metrics under dataset shifts or adversarial perturbations for i.i.d.\ inputs \citep{dataset-shift, robustness-uncertainty-dirichlet}. In contrast with all these approaches, this work studies uncertainty quantification for classification of \emph{interdependent nodes}.

\paragraph{Uncertainty for graphs.} Notably, the recent survey \citep{review-uncertainty-dl} points out that there is only a limited number of studies on uncertainty quantification on GNN and semi-supervised learning. Moreover, they recommend proposing new methods. \emph{\underline{desiderata:}} To the best of our knowledge, only \citep{Eswaran2017} proposed explicit desiderata for node classification for non-attributed graphs. They expect disconnected nodes to recover prior predictions and nodes with higher beliefs to be more convincing. In this work, we clarify the desired uncertainty estimation for node classification on attributed graphs based on \emph{motivated and explicit desiderata}. \emph{\underline{Methods:}} The largest family of models for uncertainty for graphs are dropout- or Bayesian-based methods. Important examples propose to drop or assign probabilities to edges \citep{Rong2019, Chen2018, Hasanzadeh2020, Dallachiesa2014, Hu2017}. Further works proposed to combine the uncertainty on the graph structure with uncertainty on the transformation weights similarly to BNN \citep{Elinas2019, Zhang2019b, Pal2019a, Pal2019b}. Importantly, these models do not directly quantify uncertainty on the prediction. Similarly to the i.i.d.\ case, a second family of models focuses on deterministic uncertainty quantification. Important examples mostly use Graph Gaussian Processes, which do not easily scale to large graphs \citep{Ng2018, Zhi2020, Liu2020c, Borovitskiy2020}. Only \citep{Zhao2020} explicitly parameterized a Dirichlet conjugate prior. They combined it with multiple components (Graph-Based Kernel, dropout, Teacher Network, loss regularizations) which cannot easily distinguish between uncertainty without and with network effects. In contrast, \GPNacro{} is a simple approach based on conjugate prior parametrization and disentangles uncertainty with and without network effects. \emph{\underline{Evaluation:}} The evaluation of most of those methods was not focused on the quality of the uncertainty estimates but on the target task metrics (e.g. accuracy for classification, distance to ground truth for regression). Some methods focus on robustness of the target task metrics against adversarial perturbations \citep{GNNBook-ch8-gunnemann, zugner2018adversarial, zugner2019adversarial}. Other methods only relied on uncertainty quantification to build more robust models \citep{Zhu2019, Feng2020}. For node classification, only few works evaluated uncertainty by using Left-Out classes or detection of missclassified samples \citep{Zhao2020}, active learning \cite{Ng2018} or visualization \citep{Borovitskiy2020}. Note that proposed uncertainty evaluations on molecules at graph level \citep{Zhang2019, Ryu2019, Akita2018, uncertainty-nn-molecules, uncertainty-material-prediction} is an orthogonal problem. In this work, we propose a \emph{sound and extensive evaluation} for uncertainty in node classification. It distinguishes between OOD nodes w.r.t.\ features and structure, and graph dataset shifts w.r.t.\ the percentage of perturbed node features and the percentage of perturbed edges.
