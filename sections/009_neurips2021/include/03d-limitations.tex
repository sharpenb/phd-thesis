\subsection{Limitations \& Impact} \label{sec:limitations}

\textbf{OOD data close to ID data.} While \GPNacro{} is guaranteed to provide consistent uncertainty estimates for nodes with extreme OOD features, it does not guarantee any specific uncertainty estimation behavior for OOD data close to ID data. Note that there exist two possible desired behaviors for OOD close to ID data: being robust to small dataset shifts \citep{Ovadia2019, confidence-calibrated-adversarial} or detect near OOD data \citep{contrastive-ood, robustness-uncertainty-dirichlet, attack-detection}. The duality of these two views makes unclear what would be the desired behavior even for i.i.d. data.

\looseness=-1
\textbf{Non-homophilic uncertainty.} Our approach assumes that connected nodes are likely to have similar uncertainty estimates as defined in Ax.~\ref{ax:certainty_network_epistemic} and Ax.~\ref{ax:certainty_network_aleatoric}. Contrary to \cite{heterophily-gnn}, we do not tackle the problem of heterophilic graphs where two neighboring nodes might reasonably have different uncertainty estimates. 

\textbf{Task-specific OOD.} Density estimation is shown to be inappropriate for OOD detection when acting directly on raw images \cite{typicality_OOD_generative, anomaly-detection, deep-generative} or on arbitrarily transformed space \cite{perfect-density-no-ood-guarantee}. One of the reasons is that normalizing flows learn pixel correlations in images. This phenomena  does not happen for tabular data with more semantic features \citep{Kirichenko2020}. First note that, similarly to tabular data, semantic node features are less likely to suffer from the same flaws. Second, following previous works \citep{charpentier2020, NatPN2021, Kirichenko2020, density-states-ood, contrastive-ood}, \GPNacro{} mitigates this issue by using density estimation on a latent space which is low-dimensional and task-specific. Nonetheless, we emphasize that \GPNacro{} provides predictive uncertainty estimates which depends on the considered task i.e. OOD data w.r.t. features which are not useful for the specific task are likely not to be encoded in the latent space, and thus not to be detected.

\textbf{Broader Impact.}\label{sec:broader-impact}
The Assessment List for Trustworthy AI (ALTAI) \cite{trustworthy-ai} includes robustness, safety, and accountability. Uncertainty estimation is a key element to make AI systems follow these values. For example. an automated decision maker should know when it does not know. In this regard, \GPNacro{} significantly improves the reliability of predictions on interdependent data under perturbations even though a user should not blindly rely on it. Further, ALTAI also mentions privacy and fairness. Therein, we raise awareness on the risk of using interconnected information which can amplify privacy or fairness violation in the presence of personal data.