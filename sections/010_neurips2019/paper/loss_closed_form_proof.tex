\section{Computation of the approximation for the \UncertaintyLoss of \GPModel} \label{loss_closed_form_proof}

Given true categorical distribution $\bm{p}_\IndexEvent^*,$ and predicted $\bm{p}_\IndexEvent(\DeltaTime),$ the \UncertaintyLoss can be calculated as in Eq.\ \ref{eq:loss}. For the \GPModel model $\bm{p}_\IndexEvent(\DeltaTime)=\text{softmax}(\bm{z}_\IndexEvent(\DeltaTime))$, where $\bm{z}_\IndexEvent(\DeltaTime)$ are logits that come from a Gaussian process and follow a normal distribution $\mathcal{N}(\bm{\mu}_\IndexEvent(\DeltaTime), \bm{\Sigma}_\IndexEvent(\DeltaTime)),$. Therefore, $\exp(\bm{z}_\IndexEvent(\DeltaTime))$ follows a log-normal distribution. We will use this to derive an approximation of the loss. From now on, we omit $\DeltaTime$ from the equations. Mean and variance for $\smash{\sum_\IndexClass^\NbClasses \exp(\bm{z}_{\IndexClass_\IndexEvent})}$ are then:
\begin{equation}
\begin{split}
    \E \left[ \sum\nolimits_\IndexClass^\NbClasses \exp(\bm{z}_{\IndexClass_\IndexEvent}) \right] &= \sum\nolimits_\IndexClass^\NbClasses \exp(\bm{\mu}_{\IndexClass_\IndexEvent} + \bm{\sigma}_{\IndexClass_\IndexEvent}^2 / 2) \\
    \textbf{Var}\left[ \sum\nolimits_{\IndexClass_\IndexEvent}^\NbClasses \exp(\bm{z}_{\IndexClass_\IndexEvent})\right] &= \sum\nolimits_{\IndexClass_\IndexEvent}^\NbClasses (\exp(\sigma_{\IndexClass_\IndexEvent}^2) - 1) \exp(2 \bm{\mu}_{\IndexClass_\IndexEvent} + \bm{\sigma}_{\IndexClass_\IndexEvent}^2)
\end{split}\label{eq:log-normal-moments}
\end{equation}
The expectation of the cross entropy loss given that logits are following a normal distribution is
\begin{equation}\label{eq:cross-entropy-expectation}
    \mathcal{L}_\IndexEvent^{\text{UCE}} =
    \E[\mathcal{L}_\IndexEvent^{\text{CE}}]
        = \E[\log({\exp(\bm{z}_{\IndexClass_\IndexEvent})})] - \E \left[ \log\left( \sum\nolimits_\IndexClass^\NbClasses \exp(\bm{z}_{\IndexClass_\IndexEvent}) \right) \right]
\end{equation}
In general, given a random variable $x$, we can approximate expectation of $\log x$ by performing a second order Taylor
expansion around the mean $\mu$:
\begin{equation}
\begin{split}
    \E[\log x]
        &\approx \E \Big[ \log \mu +
        \underbrace{\frac{(\log \mu)'}{1!}(x - \mu)}_{\E[x - \mu] = 0} +
        \frac{(\log \mu)''}{2!}(x - \mu)^2 \Big] \\
        &\approx \E[\log \mu] - \frac{\textbf{Var}[x]}{2 \mu^2}
\end{split}\label{eq:cross-entropy-expectation-taylor}
\end{equation}
Using \ref{eq:cross-entropy-expectation-taylor} together with \ref{eq:log-normal-moments} and plugging into \ref{eq:cross-entropy-expectation} we get a closed-form solution for the loss for event $\IndexEvent$:
\small
\begin{equation} \label{eq:gp_loss}
    \mathcal{L}_\IndexEvent^{\text{UCE}}
    \approx \mu_{\IndexClass_\IndexEvent}(\DeltaTime_\IndexEvent^*) - \log \Big( \sum_\IndexClass^\NbClasses \exp(\mu_\IndexClass(\DeltaTime_\IndexEvent^*) + \sigma_\IndexClass^2(\DeltaTime_\IndexEvent^*) / 2) \Big) +
        \frac{\sum_\IndexClass^\NbClasses (\exp(\sigma_\IndexClass^2(\DeltaTime_\IndexEvent^*)) - 1) \exp(2 \mu_\IndexClass(\DeltaTime_\IndexEvent^*) + \sigma_\IndexClass^2(\DeltaTime_\IndexEvent^*))}
        {2 \Big( \sum_\IndexClass^\NbClasses \exp(\mu_\IndexClass(\DeltaTime_\IndexEvent^*) + \sigma_\IndexClass^2(\DeltaTime_\IndexEvent^*) / 2) \Big)^2}
\end{equation}
\normalsize
