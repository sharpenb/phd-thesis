\vspace{-3mm}
\section{Related Work}
\label{sec:related_work_011}

In this section, we cover the related work for aleatoric and epistemic uncertainty estimation for RL. 
% To this end, we review implicit \emph{desiderata} for aleatoric and epistemic uncertainty, RL \emph{methods} using uncertainty estimates and the existing \emph{evaluation} methodology to validate the quality of the uncertainty estimates in practice. 
We refer the reader to the survey \cite{review-uncertainty-dl} for an exhaustive overview on uncertainty estimation. 

\underline{\textit{Desiderata:}} The notion of \emph{risk} is well studied in RL and closely connected to the notion of uncertainty. Risk-sensitive RL usually aims at reducing the number of failures at training time for safer RL \cite{risk-sensitive-rl, risk-constrained-rl-percentile, risk-sensitive-mdp, safe-rl-survey}. In particular, \cite{risk-uncertainty-deep-rl, rl-risk-sample-trade-off, epistemic-risk} discuss the trade-off between risk-sensitivity and sample efficiency at training time. Distributional RL methods expect that accounting for aleatoric uncertainty allows to achieve higher returns. Further, \cite{epistemic-pomdp} aim at improving generalization at testing time within the Bayesian RL framework. In SL, the predicted uncertainty is expected to increase further from training data \citep{provable-uncertainty, natpn, bayesian-a-bit, graph-postnet}. None of these previous works give \emph{explicit} desiderata for both \emph{aleatoric} and \emph{epistemic} \emph{uncertainty} in RL at both \emph{training} and \emph{testing} \emph{time}. 

\underline{\textit{Models:}} The related work for uncertainty-aware model in RL is rich as shown in surveys on distributional and Bayesian  RL \cite{bayesian-rl, distributional-rl}. Distributional RL \cite{distributional-rl, nonparametric-return-distribution, distributional-rl-prespective, iqn} achieves higher returns by learning the distribution of return which generally captures the aleatoric uncertainty \cite{information-directed-exploration-deep-rl}. Bayesian RL methods includes sampling-based methods models such as on dropout \cite{dropout, uncertainty-rl-collision-avoidance} and ensembles \cite{bootstrapped-dqn, randomized-prior-functions, safe-rl-model-uncertainty, rl-active-learning, epistemic-pomdp}. These methods are often combined with bootstrapping during training. In particular, \cite{risk-uncertainty-deep-rl} proposed to decompose aleatoric and epistemic uncertainty to the cost of multiple trained networks and \cite{Depeweg2018} decompose aleatoric and epistemic uncertainty with latent variables for model-based RL. Bayesian RL also includes Gaussian processes \citep{gp-rl, rl-gp} and more specifically the deep kernel learning method \citep{deep-rl-deep-kernel-leanring} which requires storing uncertainty estimates in the experience replay buffer during training. Unlike RL, SL includes many uncertainty methods using deep kernel learning \citep{due, duq, simple-baseline-uncertainty} and evidential network \cite{charpentier2020, natpn, graph-postnet, PriorNetworks, regression-priornet, evidential-regression, robustness-uncertainty-dirichlet}. In contrast, we look at \emph{both} sampled-based and sampled-free uncertainty methods for \emph{aleatoric} and \emph{epistemic} uncertainty estimation with \emph{minimal} modification to the training procedure of the RL agent, thus ensuring easy adaptation of new uncertainty quantification techniques from SL to RL. 

\underline{\textit{Evaluation:}} \cite{bsuite-rl, testbed-rl} proposed to evaluate uncertainty in RL by focusing on joint predictive distributions instead of marginal distributions. Many works \cite{sample-efficient-ac, sample-efficient-rl-stochastic-ensemble, q-prop-sample-efficient, rl-fast-slow} used sample efficiency as evaluation method. Further, previous works proposed generalization benchmarks for RL \cite{generalization-rl-survey, assessing-generalization-rl, procgen}. Finally, \cite{ood-dynamic-benchmark, benchmark-ood-detection-rl} have recently proposed benchmarks for OOD detection relevant to RL. In contrast, we propose a simple evaluation method which \emph{jointly} look at \emph{multiple} tasks relevant to real-world applications of uncertainty in RL. It covers epistemic uncertainty tracking and sample efficiency at training time, and generalization and OOD detection at testing time. In particular, we evaluate the trade-off between OOD generalization \cite{ood-generalization-survey} and OOD detection \cite{ood-detection-survey}.