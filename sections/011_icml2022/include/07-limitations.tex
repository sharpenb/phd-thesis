\section{Limitations}
\label{sec:limitations_011}

\looseness=-1
\underline{\textit{Desiderata:}.} Our desiderata, similar to \cite{graph-postnet, desiderata-ml-lifecycle, overview-interpretable-ml}, are designed to be application and model agnostic. In practice, the desiderata should be instantiated with formal definitions and could be customized depending on the application. \underline{\textit{Models:}} To validate the key contributions, similar to \cite{distributional-rl-prespective, iqn, bootstrapped-dqn}, we restrict our experiments to DQNs. However, the four uncertainty methods essentially modify the encoder architecture, it is possible to adapt them to other model-free RL methods such as PPO \cite{ppo} and A2C \cite{a2c}. \underline{\textit{Evaluation:}} Our approach focuses on a simple and task-diverse evaluation methodology for uncertainty estimation. Contrary to \cite{procgen}, we do not focus on scaling RL methods to more complex tasks in this paper. %\underline{\textit{Broader impact:}} Our framework discusses the benefit of using uncertainty estimation to create robust and safe RL methods which corroborate with the Assessment List for Trustworthy AI \cite{trustworthy-ai}. Although, there is always a risk that this framework does not fully capture the real-world complexity, thus encouraging practitioners to proactively validate their models in the real-world.
