\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
\input{include/00-packages}
%\usepackage{neurips_2021}
\usepackage[nonatbib]{neurips_2022}
\input{include/00-commands}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.:
%\usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2021}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\usepackage[backend=bibtex,natbib=true,style=ieee,mincitenames=1,maxcitenames=2,maxbibnames=20,url=false,doi=false,dashed=false]{biblatex}
\AtEveryBibitem{
    \ifentrytype{inproceedings}{
         \clearlist{address}
         \clearlist{publisher}
         \clearname{editor}
         \clearlist{organization}
         \clearfield{url}  
         \clearfield{doi}  
         \clearfield{pages}  
         \clearlist{location}
         \clearlist{month}
     }{}
     \ifentrytype{article}{
         \clearlist{address}
         \clearlist{publisher}
         \clearname{editor}
         \clearlist{organization}
         \clearfield{url}  
         \clearfield{doi}  
         \clearlist{location}
     }{}
 }
 \addbibresource{bibliography.bib}

%\title{Transferring Uncertainty Quantification from Supervised to Reinforcement Learning}
\title{Disentangling Epistemic and Aleatoric Uncertainty in Reinforcement Learning}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  %Bertrand Charpentier, Stephan G\"unnemann\\
  %Technical University of Munich, Germany\\
  %\texttt{\{charpent, guennemann\}@in.tum.de} \\
}

\begin{document}

\maketitle

\begin{abstract}
    
    \looseness=-1
    Characterizing \emph{aleatoric} and \emph{epistemic} uncertainty on the predicted rewards can help in building reliable reinforcement learning (RL) systems. Aleatoric uncertainty results from the irreducible environment stochasticity leading to inherently risky states and actions. Epistemic uncertainty results from the limited information accumulated during learning to make informed decisions. Characterizing aleatoric and epistemic uncertainty can be used to speed up learning in a training environment, improve generalization to similar testing environments, and flag unfamiliar behavior in anomalous testing environments. In this work, we introduce a framework for disentangling aleatoric and epistemic uncertainty in RL. \textbf{(1)} We first define four \emph{desiderata} that capture the desired behavior for aleatoric and epistemic uncertainty estimation in RL at both training and testing time. \textbf{(2)} We then present four RL \emph{models} inspired by supervised learning (i.e., Monte Carlo dropout, ensemble, deep kernel learning models, and evidential networks) to instantiate aleatoric and epistemic uncertainty. Finally, \textbf{(3)} we propose a practical \emph{evaluation} method to evaluate uncertainty estimation in model-free RL based on detection of out-of-distribution environments and generalization to perturbed environments. We present \emph{theoretical} and \emph{experimental} evidence to validate that carefully equipping model-free RL agents with supervised learning uncertainty methods can fulfill our desiderata.
    
\end{abstract}

\input{include/01-introduction}
\input{include/02-setup}
\input{include/03-desiderata}
\input{include/04-models}
\input{include/05-evaluation}
\input{include/06-related_works}
\input{include/07-limitations}
\input{include/08-conclusion}

\printbibliography

\newpage

%\input{include/xx-checklist}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\input{include/xx-appendix}

\end{document}
